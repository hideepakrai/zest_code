{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651c16af-ab8b-4f42-a170-08e72e0f3533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionXLControlNetInpaintPipeline, ControlNetModel\n",
    "from rembg import remove\n",
    "from PIL import Image\n",
    "import torch\n",
    "from ip_adapter import IPAdapterXL\n",
    "from ip_adapter.utils import register_cross_attention_hook, get_net_attn_map, attnmaps2images\n",
    "from PIL import Image, ImageChops\n",
    "import numpy as np\n",
    "\n",
    "def image_grid(imgs, rows, cols):\n",
    "    assert len(imgs) == rows*cols\n",
    "\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    grid_w, grid_h = grid.size\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4810ab9-f6f3-4a27-aa01-7076ac3eefff",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_path = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "image_encoder_path = \"models/image_encoder\"\n",
    "ip_ckpt = \"sdxl_models/ip-adapter_sdxl_vit-h.bin\"\n",
    "controlnet_path = \"diffusers/controlnet-depth-sdxl-1.0\"\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fe3d8e3-a786-434d-8a45-14c8ebee0979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 19 files:   0%|          | 0/19 [00:00<?, ?it/s]Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Fetching 19 files: 100%|██████████| 19/19 [00:13<00:00,  1.39it/s]\n",
      "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:26<00:00,  3.77s/it]\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# load SDXL pipeline\n",
    "controlnet = ControlNetModel.from_pretrained(controlnet_path, variant=\"fp16\", use_safetensors=True, torch_dtype=torch.float16).to(device)\n",
    "pipe = StableDiffusionXLControlNetInpaintPipeline.from_pretrained(\n",
    "    base_model_path,\n",
    "    controlnet=controlnet,\n",
    "    use_safetensors=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    add_watermarker=False,\n",
    ").to(device)\n",
    "pipe.unet = register_cross_attention_hook(pipe.unet)\n",
    "\n",
    "ip_model = IPAdapterXL(pipe, image_encoder_path, ip_ckpt, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afce34a5-7450-4f9f-a64a-3e04ffed6e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "obj = 'AAA1111'\n",
    "texture = 'cup_glaze'\n",
    "target_image_path = 'demo_assets/input_imgs/' + obj + '.jpg'  # Replace with your image path\n",
    "target_image = Image.open(target_image_path).convert('RGB')\n",
    "rm_bg = remove(target_image)\n",
    "# output.save(output_path)\n",
    "target_mask = rm_bg.convert(\"RGB\").point(lambda x: 0 if x < 1 else 255).convert('L').convert('RGB')# Convert mask to grayscale\n",
    "\n",
    "# Ensure mask is the same size as image\n",
    "\n",
    "# mask = ImageChops.invert(mask)\n",
    "# Generate random noise for the size of the image\n",
    "noise = np.random.randint(0, 256, target_image.size + (3,), dtype=np.uint8)\n",
    "noise_image = Image.fromarray(noise)\n",
    "mask_target_img = ImageChops.lighter(target_image, target_mask)\n",
    "invert_target_mask = ImageChops.invert(target_mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "057d1cc1-a2bf-4384-89c3-58aa5c350df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageEnhance\n",
    "gray_target_image = target_image.convert('L').convert('RGB')\n",
    "gray_target_image = ImageEnhance.Brightness(gray_target_image)\n",
    "\n",
    "# Adjust brightness\n",
    "# The factor 1.0 means original brightness, greater than 1.0 makes the image brighter. Adjust this if the image is too dim\n",
    "factor = 1.0  # Try adjusting this to get the desired brightness\n",
    "\n",
    "gray_target_image = gray_target_image.enhance(factor)\n",
    "grayscale_img = ImageChops.darker(gray_target_image, target_mask)\n",
    "img_black_mask = ImageChops.darker(target_image, invert_target_mask)\n",
    "grayscale_init_img = ImageChops.lighter(img_black_mask, grayscale_img)\n",
    "init_img = grayscale_init_img\n",
    "\n",
    "ip_image = Image.open(\"demo_assets/material_exemplars/\" + texture + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2f16546-eefe-4313-95a7-f840aeee3f59",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\inetpub\\\\wwwroot\\\\zest_code\\\\demo_assets\\\\depths\\\\AAA1111.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m np_image = np.array(\u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdemo_assets/depths/\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m.jpg\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m      2\u001b[39m np_image = (np_image / \u001b[32m256\u001b[39m).astype(\u001b[33m'\u001b[39m\u001b[33muint8\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m depth_map = Image.fromarray(np_image).resize((\u001b[32m1024\u001b[39m,\u001b[32m1024\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\inetpub\\wwwroot\\zest_code\\venv\\Lib\\site-packages\\PIL\\Image.py:3431\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(fp, mode, formats)\u001b[39m\n\u001b[32m   3428\u001b[39m     filename = os.path.realpath(os.fspath(fp))\n\u001b[32m   3430\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[32m-> \u001b[39m\u001b[32m3431\u001b[39m     fp = \u001b[43mbuiltins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3432\u001b[39m     exclusive_fp = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   3433\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'C:\\\\inetpub\\\\wwwroot\\\\zest_code\\\\demo_assets\\\\depths\\\\AAA1111.jpg'"
     ]
    }
   ],
   "source": [
    "np_image = np.array(Image.open('demo_assets/depths/' + obj + '.jpg'))\n",
    "np_image = (np_image / 256).astype('uint8')\n",
    "\n",
    "depth_map = Image.fromarray(np_image).resize((1024,1024))\n",
    "\n",
    "init_img = init_img.resize((1024,1024))\n",
    "mask = target_mask.resize((1024, 1024))\n",
    "grid = image_grid([target_mask.resize((256, 256)), ip_image.resize((256, 256)), init_img.resize((256, 256)), depth_map.resize((256, 256))], 1, 4)\n",
    "\n",
    "# Visualize each input individually\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccfdc71f-3913-4772-a68f-2266c1f50af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:12<00:00,  2.31it/s]\n"
     ]
    }
   ],
   "source": [
    "num_samples = 1\n",
    "images = ip_model.generate(pil_image=ip_image, image=init_img, control_image=depth_map, mask_image=mask, controlnet_conditioning_scale=0.9, num_samples=num_samples, num_inference_steps=30, seed=42)\n",
    "images[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651fc615-b21d-4a95-985d-9f1eeb53ef49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
